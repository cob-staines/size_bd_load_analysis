---
title: "env_timeseries"
format: html
---

```{r}
librarian::shelf(tidyverse, dbplyr, here, janitor, RPostgres, DBI, RIBBiTR-BII/ribbitrrr, brms, tidybayes, ggplot2)

ts_in = read_csv(here("python", "gee_env_pull", "data", "gee_chirps_modis_data_025.csv"))

```

# window function
```{r}
sliding_window <- function(df, ts_col_name, window_size, f, result_col_name) {
  ts_sym <- sym(ts_col_name)
  res_sym <- sym(result_col_name)
  
  df %>%
    group_modify(~{
      n <- nrow(.x)
      ts_vals <- pull(.x, !!ts_sym)
      agg_vals <- map_dbl(seq_len(n), function(i) {
        if (i >= window_size) {
          window_vals <- ts_vals[(i - window_size + 1):i]
          f(window_vals)
        } else {
          NA_real_
        }
      })
      .x[[result_col_name]] <- agg_vals
      .x
    })
}
```

```{r}
#| warning: false

n_val = function(x) sum(!is.na(x))
na_mean = function(x) mean(x, na.rm = TRUE)
na_max = function(x) max(x, na.rm = TRUE)

win_fun_10 = ts_in %>%
  arrange(site, date) %>%
  group_by(site) %>%
  sliding_window("precipitation_mm", 10, n_val, "precip_mm_20_day_n") %>%
  sliding_window("precipitation_mm", 10, sum, "precip_mm_20_day_sum") %>%
  sliding_window("temperature_c", 10, n_val, "temp_c_20_day_n") %>%
  sliding_window("temperature_c", 10, na_mean, "temp_c_20_day_mean") %>%
  sliding_window("temperature_c", 10, na_max, "temp_c_20_day_max") %>%
  ungroup()

win_fun_20 = ts_in %>%
  arrange(site, date) %>%
  group_by(site) %>%
  sliding_window("precipitation_mm", 20, n_val, "precip_mm_20_day_n") %>%
  sliding_window("precipitation_mm", 20, sum, "precip_mm_20_day_sum") %>%
  sliding_window("temperature_c", 20, n_val, "temp_c_20_day_n") %>%
  sliding_window("temperature_c", 20, na_mean, "temp_c_20_day_mean") %>%
  sliding_window("temperature_c", 20, na_max, "temp_c_20_day_max") %>%
  ungroup()

win_fun_30 = ts_in %>%
  arrange(site, date) %>%
  group_by(site) %>%
  sliding_window("precipitation_mm", 30, n_val, "precip_mm_20_day_n") %>%
  sliding_window("precipitation_mm", 30, sum, "precip_mm_20_day_sum") %>%
  sliding_window("temperature_c", 30, n_val, "temp_c_20_day_n") %>%
  sliding_window("temperature_c", 30, na_mean, "temp_c_20_day_mean") %>%
  sliding_window("temperature_c", 30, na_max, "temp_c_20_day_max") %>%
  ungroup()

win_fun_40 = ts_in %>%
  arrange(site, date) %>%
  group_by(site) %>%
  sliding_window("precipitation_mm", 40, n_val, "precip_mm_20_day_n") %>%
  sliding_window("precipitation_mm", 40, sum, "precip_mm_20_day_sum") %>%
  sliding_window("temperature_c", 40, n_val, "temp_c_20_day_n") %>%
  sliding_window("temperature_c", 40, na_mean, "temp_c_20_day_mean") %>%
  sliding_window("temperature_c", 40, na_max, "temp_c_20_day_max") %>%
  ungroup()

bd_env = bd_model %>%
  select(site,
         date,
         taxon_capture,
         bd_detected_co,
         log_bd_load_co_density) %>%
  mutate(bd_detected_bi = as.numeric(bd_detected_co)) %>%
  left_join(win_fun_40, by = c("site", "date")) %>%
  arrange(site, date)

prev_precip = cor.test(bd_env$bd_detected_bi, bd_env$precip_mm_20_day_sum, method = "spearman")
prev_temp_mean = cor.test(bd_env$bd_detected_bi, bd_env$temp_c_20_day_mean, method = "spearman")
prev_temp_max = cor.test(bd_env$bd_detected_bi, bd_env$temp_c_20_day_max, method = "spearman")

load_precip = cor.test(bd_env %>%
                         filter(bd_detected_co) %>%
                         pull(log_bd_load_co_density),
                       bd_env %>%
                         filter(bd_detected_co) %>%
                         pull(precip_mm_20_day_sum), method = "pearson")
load_temp_mean = cor.test(bd_env %>%
                            filter(bd_detected_co) %>%
                            pull(log_bd_load_co_density),
                       bd_env %>%
                         filter(bd_detected_co) %>%
                         pull(temp_c_20_day_mean), method = "pearson")
load_temp_max = cor.test(bd_env %>%
                           filter(bd_detected_co) %>%
                           pull(log_bd_load_co_density),
                       bd_env %>%
                         filter(bd_detected_co) %>%
                         pull(temp_c_20_day_max), method = "pearson")

prev_precip
prev_temp_mean
prev_temp_max
load_precip
load_temp_mean
load_temp_max

```

correlation across window size
```{r}
win_corr = function(df_a, df_b, window_l, window_f, col_a, col_b, cor_method) {
  col_a_sym <- rlang::ensym(col_a)
  col_b_sym <- rlang::ensym(col_b)
  
  df_win = df_a %>%
    group_by(site) %>%
    sliding_window(col_a_sym, window_l, window_f, "window")
  
  df_x = df_b %>%
    left_join(df_win, by = c("site", "date")) %>%
    select("window",
           col_b_sym)
  
  test_n = cor.test(df_x %>%
                      pull("window"),
                    df_x %>%
                      pull(col_b_sym), method = cor_method)
  return(test_n$estimate[[1]])
}

na_mean = function(x) {
  if (all(is.na(x)))
    return(NA)
  else {
    return(mean(x, na.rm = TRUE))
  }
}

na_max = function(x) {
  if (all(is.na(x)))
    return(NA)
  else {
    return(max(x, na.rm = TRUE))
  }
}


bd_env = bd_model %>%
  select(site,
         date,
         taxon_capture,
         bd_detected_co,
         log_bd_load_co_density) %>%
  mutate(bd_detected_bi = as.numeric(bd_detected_co))

window_max = 180

prev_precip <- tibble(window_l = 1:window_max) %>%
  mutate(output = map(window_l, ~win_corr(ts_in, bd_env, .x, sum, "precipitation_mm", "bd_detected_bi", "spearman")),
         var = "precipitation_sum")
prev_precip$output = unlist(prev_precip$output)

prev_temp_mean <- tibble(window_l = 1:window_max) %>%
  mutate(output = map(window_l, ~win_corr(ts_in, bd_env, .x, na_mean, "temperature_c", "bd_detected_bi", "spearman")),
         var = "temperature_mean")
prev_temp_mean$output = unlist(prev_temp_mean$output)

prev_temp_max <- tibble(window_l = 1:window_max) %>%
  mutate(output = map(window_l, ~win_corr(ts_in, bd_env, .x, na_max, "temperature_c", "bd_detected_bi", "spearman")),
         var = "temperature_max")
prev_temp_max$output = unlist(prev_temp_max$output)

load_precip <- tibble(window_l = 1:window_max) %>%
  mutate(output = map(window_l, ~win_corr(ts_in, bd_env %>% filter(bd_detected_co), .x, sum, "precipitation_mm", "log_bd_load_co_density", "pearson")),
         var = "precipitation_sum")
load_precip$output = unlist(load_precip$output)

load_temp_mean <- tibble(window_l = 1:window_max) %>%
  mutate(output = map(window_l, ~win_corr(ts_in, bd_env %>% filter(bd_detected_co), .x, na_mean, "temperature_c", "log_bd_load_co_density", "pearson")),
         var = "temperature_mean")
load_temp_mean$output = unlist(load_temp_mean$output)

load_temp_max <- tibble(window_l = 1:window_max) %>%
  mutate(output = map(window_l, ~win_corr(ts_in, bd_env %>% filter(bd_detected_co), .x, na_max, "temperature_c", "log_bd_load_co_density", "pearson")),
         var = "temperature_max")
load_temp_max$output = unlist(load_temp_max$output)

prev_df = bind_rows(prev_precip,
                    prev_temp_mean,
                    prev_temp_max)

ggplot(prev_df, aes(x = window_l, y = output, color = var)) +
  geom_hline(yintercept = 0) +
  geom_line()

load_df = bind_rows(load_precip,
                    load_temp_mean,
                    load_temp_max)

ggplot(load_df, aes(x = window_l, y = output, color = var)) +
  geom_hline(yintercept = 0) +
  geom_line()

```


correlation analysis
```{r}
bd_env = bd_model %>%
  select(site,
         date,
         taxon_capture,
         bd_detected_co,
         log_bd_load_co_density) %>%
  mutate(bd_detected_bi = as.numeric(bd_detected_co)) %>%
  left_join(ts_in, by = c("site", "date")) %>%
  arrange(site, date)

cross_cor_prev <- function(df, lag_lookup, col_a, col_b, max_lag) {
  col_a_sym <- rlang::ensym(col_a)
  col_a_lag = paste0(col_a, ".lag")
  col_b_sym <- rlang::ensym(col_b)
  
  map_dfr(0:max_lag, function(lag) {
    result_df <- df %>%
      mutate(date_lag = date - lag) %>%
      left_join(lag_lookup, by = c("site", "date_lag" = "date"), suffix = c("", ".lag"))
    
    # Use pull() to extract columns, as symbols or string
    corr <- cor(result_df %>% pull(!!col_a_lag), result_df %>% pull(!!col_b_sym), use = "pairwise.complete.obs", method = "spearman")
    tibble(lag = lag, correlation = corr)
  })
}

cross_cor_load <- function(df, lag_lookup, col_a, col_b, max_lag) {
  col_a_sym <- rlang::ensym(col_a)
  col_a_lag = paste0(col_a, ".lag")
  col_b_sym <- rlang::ensym(col_b)
  
  map_dfr(0:max_lag, function(lag) {
    result_df <- df %>%
      mutate(date_lag = date - lag) %>%
      left_join(lag_lookup, by = c("site", "date_lag" = "date"), suffix = c("", ".lag"))
    
    # Use pull() to extract columns, as symbols or string
    corr <- cor(result_df %>% pull(!!col_a_lag), result_df %>% pull(!!col_b_sym), use = "pairwise.complete.obs")
    tibble(lag = lag, correlation = corr)
  })
}

precip_prev_xc = cross_cor_prev(bd_env, ts_in, "precipitation_mm", col_b = "bd_detected_bi", 90) %>%
  mutate(vars = "Precip x Bd-detection")

precip_load_xc = cross_cor_load(bd_env %>%
                          filter(bd_detected_co), ts_in, "precipitation_mm", col_b = "log_bd_load_co_density", 90) %>%
  mutate(vars = "Precip x Bd-load")

precip_xc = bind_rows(precip_prev_xc,
                      precip_load_xc)

ggplot(precip_xc, aes(x = lag, y = correlation, color = vars)) +
  geom_line() +
  geom_point() +
  geom_hline(yintercept = 0) + 
  labs(title = "Correlation between A and B at varying lags")

temp_prev_xc = cross_cor_prev(bd_env, ts_in, "temperature_c", col_b = "bd_detected_bi", 90) %>%
  mutate(vars = "Temp x Bd-detection")

temp_load_xc = cross_cor_load(bd_env %>%
                          filter(bd_detected_co), ts_in, "temperature_c", col_b = "log_bd_load_co_density", 90) %>%
  mutate(vars = "Temp x Bd-load")

temp_xc = bind_rows(temp_prev_xc,
                    temp_load_xc)

ggplot(temp_xc, aes(x = lag, y = correlation, color = vars)) +
  geom_line() +
  geom_point() +
  geom_hline(yintercept = 0) + 
  labs(title = "Correlation between A and B at varying lags")


```

# values (not correlation)
```{r}
df = bd_env
lag_lookup = ts_in
col_a_breaks = seq(10, 30, by = 1)
col_a = "temperature_c"
max_lag = 30
col_b = "log_bd_load_co_density"

lag_matrix <- function(df, lag_lookup, col_a, col_b, max_lag, col_a_breaks) {
  col_a_sym <- rlang::ensym(col_a)
  col_a_lag = rlang::sym(paste0(col_a, ".lag"))
  col_b_sym <- rlang::ensym(col_b)
  
  lag_df = tibble(lag_days = seq(0:max_lag))
  result_df = df %>%
    cross_join(lag_df) %>%
    mutate(date_lag = date - lag_days) %>%
    left_join(lag_lookup, by = c("site", "date_lag" = "date"), suffix = c("", ".lag")) %>%
    mutate(var_bin = cut(!!col_a_lag, breaks = col_a_breaks, include.lowest = TRUE, right = FALSE)) %>%
    group_by(lag_days, var_bin) %>%
    summarise(n = n(),
              mean_val = mean(!!col_b_sym, na.rm = TRUE),
              .groups = 'drop')
}

plot_lag_matrix = function(df, env_var_name, bd_var_name) {
  max_dev = max(abs(c(min(df$mean_val), max(df$mean_val)) - mean(df$mean_val)))
  
  ggplot(df, aes(x = lag_days, y = var_bin, fill = mean_val)) +
    geom_tile() +
    theme_minimal() +
    scale_fill_gradient2(
      low = "blue",
      mid = "white",
      high = "red",
      midpoint = mean(df$mean_val),
      limits = c(mean(df$mean_val) - max_dev, mean(df$mean_val) + max_dev),
      name = "Value"
    ) +
    labs(x = "Lag Days", y = env_var_name, fill = bd_var_name)
}

lag_matrix_temp_prev = lag_matrix(bd_env, ts_in, "temperature_c", "bd_detected_bi", 90, seq(10, 40, by = 3)) %>%
  mutate(mean_dev = mean_val - mean(bd_env %>%
                                      pull(bd_detected_bi), na.rm = TRUE))

lag_matrix_temp_load = lag_matrix(bd_env %>%
                                    filter(bd_detected_co), ts_in, "temperature_c", "log_bd_load_co_density", 90, seq(10, 40, by = 3)) %>%
  mutate(mean_dev = mean_val - mean(bd_env %>%
                                      filter(bd_detected_co) %>%
                                      pull(log_bd_load_co_density), na.rm = TRUE))

lag_matrix_precip_prev = lag_matrix(bd_env, ts_in, "precipitation_mm", "bd_detected_bi", 90, seq(0, 40, by = 3)) %>%
  mutate(mean_dev = mean_val - mean(bd_env %>%
                                      pull(bd_detected_bi), na.rm = TRUE))

lag_matrix_precip_load = lag_matrix(bd_env %>%
                                    filter(bd_detected_co), ts_in, "precipitation_mm", "log_bd_load_co_density", 90, seq(0, 40, by = 3)) %>%
  mutate(mean_dev = mean_val - mean(bd_env %>%
                                      filter(bd_detected_co) %>%
                                      pull(log_bd_load_co_density), na.rm = TRUE))

plot_lag_matrix(lag_matrix_temp_prev, "Temperature C", "Bd prevalence")
plot_lag_matrix(lag_matrix_temp_load, "Temperature C", "log Bd Load")
plot_lag_matrix(lag_matrix_precip_prev, "Precipitation mm", "Bd prevalence")
plot_lag_matrix(lag_matrix_precip_load, "Precipitation mm", "log Bd Load") 

lag = 50
ggplot(bd_env %>%
         mutate(date_lag = date - lag) %>%
         left_join(lag_lookup, by = c("site", "date_lag" = "date"), suffix = c("", ".lag")), aes(y = log_bd_load_co_density)) +
  geom_point(aes(x = precipitation_mm), color = "red") +
  geom_point(aes(x = precipitation_mm.lag), color = "blue")

```


# across species
```{r}

df = bd_env
lag_lookup = ts_in
col_a = "precipitation_mm"
col_b = "bd_detected_bi"
max_lag = 90
cross_cor_prev <- function(df, lag_lookup, col_a, col_b, max_lag) {
  col_a_sym <- rlang::ensym(col_a)
  col_b_sym <- rlang::ensym(col_b)
  
  map_dfr(0:max_lag, function(lag) {
    result_df <- df %>%
      mutate(col_a_lag = dplyr::lag(!!col_a_sym, n = lag))
    
    # Use pull() to extract columns, as symbols or string
    corr <- cor(result_df$col_a_lag, result_df %>% pull(!!col_b_sym), use = "pairwise.complete.obs", method = "spearman")
    tibble(lag = lag, correlation = corr)
  })
}


```

# prewhitening
```{r}
negloglik_arma11_pooled <- function(params, zlist, estimate_mu = FALSE) {
  if (estimate_mu) {
    phi <- params[1]
    theta <- params[2]
    mu <- params[3]
    log_sigma2 <- params[4]
  } else {
    phi <- params[1]
    theta <- params[2]
    mu <- 0
    log_sigma2 <- params[3]
  }
  sigma2 <- exp(log_sigma2)
  # simple stability penalty to keep things in stationary/invertible region
  if (abs(phi) >= 0.9999 || abs(theta) >= 0.9999) return(1e10)
  sumsq <- 0
  n_effective <- 0
  for (z in zlist) {
    # skip too short series
    if (length(z) < 2 || all(is.na(z))) next
    # remove leading NAs
    z <- as.numeric(z)
    ok <- !is.na(z)
    if (sum(ok) < 2) next
    z <- z[ok]
    # conditional likelihood: start residual recursion at t=2, set a1 = 0,
    # compute residuals a_t for t=2..m and accumulate sumsq.
    m <- length(z)
    a_prev <- 0
    # we start at t = 2 .. m
    for (t in 2:m) {
      a_t <- z[t] - mu - phi * (z[t-1] - mu) - theta * a_prev
      sumsq <- sumsq + (a_t^2)
      a_prev <- a_t
    }
    n_effective <- n_effective + (m - 1L)
  }
  if (n_effective <= 0) return(1e10)
  nll <- 0.5 * n_effective * (log(2 * pi) + log(sigma2)) + 0.5 * sumsq / sigma2
  return(nll)
}

fit_pooled_arima111 <- function(replist,
                                estimate_mu = FALSE,
                                start = NULL,
                                lower = c(phi = -0.99, theta = -0.99),
                                upper = c(phi = 0.99, theta = 0.99),
                                control = list()) {
  # Build list of differenced series z = diff(y), dropping leading NA if necessary
  zlist <- lapply(replist, function(y) {
    y <- as.numeric(y)
    if (all(is.na(y))) return(numeric(0))
    # difference once preserving NA positions; use base::diff dropping NAs automatically
    # but to be safe, compute difference on non-NA sequences and reassemble NAs
    ok_idx <- which(!is.na(y))
    if (length(ok_idx) <= 1) return(numeric(0))
    # simple approach: compute diff on contiguous blocks
    z <- diff(y)
    # note: diff will coerce NA to NA for adjacent NA; we'll keep it simple and drop NA later
    return(z)
  })
  # Remove empty elements
  zlist <- Filter(function(z) length(na.omit(z)) >= 2, zlist)
  if (length(zlist) == 0) stop("No usable differenced series (need at least length 2 after differencing).")
  # starting values
  if (is.null(start)) {
    start_phi <- 0.5
    start_theta <- 0.2
    start_mu <- 0
    start_sigma <- sd(unlist(lapply(zlist, function(z) na.omit(z))), na.rm = TRUE)
  } else {
    start_phi <- start["phi"]
    start_theta <- start["theta"]
    start_mu <- ifelse(is.null(start["mu"]), 0, start["mu"])
    start_sigma <- ifelse(is.null(start["sigma"]), 1, start["sigma"])
  }
  if (estimate_mu) {
    p0 <- c(phi = start_phi, theta = start_theta, mu = start_mu, log_sigma2 = log(start_sigma^2))
    lower_b <- c(lower["phi"], lower["theta"], -Inf, -Inf)
    upper_b <- c(upper["phi"], upper["theta"], Inf, Inf)
  } else {
    p0 <- c(phi = start_phi, theta = start_theta, log_sigma2 = log(start_sigma^2))
    lower_b <- c(lower["phi"], lower["theta"], -Inf)
    upper_b <- c(upper["phi"], upper["theta"], Inf)
  }
  # run optimizer
  opt <- optim(par = p0,
               fn = negloglik_arma11_pooled,
               zlist = zlist,
               estimate_mu = estimate_mu,
               method = "L-BFGS-B",
               lower = lower_b,
               upper = upper_b,
               control = control)
  # extract estimates
  if (estimate_mu) {
    est_phi <- opt$par[1]
    est_theta <- opt$par[2]
    est_mu <- opt$par[3]
    est_sigma2 <- exp(opt$par[4])
  } else {
    est_phi <- opt$par[1]
    est_theta <- opt$par[2]
    est_mu <- 0
    est_sigma2 <- exp(opt$par[3])
  }
  # approximate SEs from Hessian (numDeriv)
  # use negative log-lik wrapper for numDeriv's hessian
  hess_ok <- try({
    hess <- numDeriv::hessian(func = negloglik_arma11_pooled, x = opt$par, zlist = zlist, estimate_mu = estimate_mu)
    vcov_mat <- try(solve(hess), silent = TRUE)
    if (inherits(vcov_mat, "try-error")) vcov_mat <- NULL
    vcov_mat
  }, silent = TRUE)
  se <- NULL
  if (!is.null(hess_ok) && is.matrix(hess_ok)) {
    se <- sqrt(diag(hess_ok))
    names(se) <- names(opt$par)
  }
  # compute conditional log-likelihood (negative of opt$value)
  logLik <- -opt$value
  out <- list(call = match.call(),
              estimates = list(phi = est_phi, theta = est_theta, mu = est_mu, sigma = sqrt(est_sigma2)),
              se = se,
              logLik = logLik,
              optim = opt,
              zlist = zlist)
  class(out) <- "pooledARIMA111"
  return(out)
}

fit_each_arima111 <- function(replist, use_forecast = FALSE) {
  out <- lapply(names(replist), function(nm) {
    y <- replist[[nm]]
    if (all(is.na(y)) || length(na.omit(y)) < 5) {
      return(data.frame(site = nm, phi = NA_real_, theta = NA_real_, sigma = NA_real_,
                        se_phi = NA_real_, se_theta = NA_real_, se_sigma = NA_real_,
                        stringsAsFactors = FALSE))
    }
    if (use_forecast && requireNamespace("forecast", quietly = TRUE)) {
      fit <- tryCatch(forecast::Arima(y, order = c(1,1,1), include.mean = FALSE), error = function(e) NULL)
      if (is.null(fit)) {
        fit <- tryCatch(stats::arima(y, order = c(1,1,1), include.mean = FALSE), error = function(e) NULL)
      }
    } else {
      fit <- tryCatch(stats::arima(y, order = c(1,1,1), include.mean = FALSE), error = function(e) NULL)
    }
    if (is.null(fit)) {
      return(data.frame(site = nm, phi = NA_real_, theta = NA_real_, sigma = NA_real_,
                        se_phi = NA_real_, se_theta = NA_real_, se_sigma = NA_real_,
                        stringsAsFactors = FALSE))
    }
    coefs <- coef(fit)
    phi <- ifelse("ar1" %in% names(coefs), coefs["ar1"], NA_real_)
    theta <- ifelse("ma1" %in% names(coefs), coefs["ma1"], NA_real_)
    sigma <- sqrt(fit$sigma2)
    # approximate se: use sqrt(diag(var.coef)) if available
    se_phi <- se_theta <- se_sigma <- NA_real_
    if (!is.null(fit$var.coef)) {
      vc <- fit$var.coef
      se_phi <- ifelse("ar1" %in% rownames(vc), sqrt(vc["ar1", "ar1"]), NA_real_)
      se_theta <- ifelse("ma1" %in% rownames(vc), sqrt(vc["ma1", "ma1"]), NA_real_)
    }
    data.frame(site = nm, phi = as.numeric(phi), theta = as.numeric(theta), sigma = sigma,
               se_phi = as.numeric(se_phi), se_theta = as.numeric(se_theta), se_sigma = as.numeric(se_sigma),
               stringsAsFactors = FALSE)
  })
  do.call(rbind, out)
}

sites = sort(unique(ts_in$site))
precip_ts = vector("list", length(sites))

for (ii in sites) {
  precip_ts[[ii]] = ts_in %>%
    filter(site == ii) %>%
    arrange(date) %>%
    pull(precipitation_mm)
}

# pooled
pooled_fit <- fit_pooled_arima111(precip_ts, estimate_mu = FALSE)
print(pooled_fit$estimates)

# individual
perfit <- fit_each_arima111(precip_ts)
print(summary(perfit$phi))
print(summary(perfit$theta))
print(summary(perfit$sigma))

# prewhitening

x = ts_in %>%
      filter(site == "altos_de_piedra") %>%
      arrange(date) %>%
      pull(precipitation_mm)
acf(x, lag.max = 90)
diff1x = diff(x, 1)
acf(diff1x, lag.max = 90, na.action = na.omit)
pacf(diff1x, lag.max = 90, na.action = na.omit)
ar1model = sarima(x,1,1,1)
ar1model
pwx=resid(ar1model$fit)
newpwy = filter(y, filter = c(1,-0.2249857,-0.9425813), sides =1)
ccf (pwx,newpwy,na.action=na.omit)

# sparse options
dates = ts_in %>%
  select(date) %>%
  distinct() %>%
  arrange(date)

sites = ts_in %>%
  select(site) %>%
  distinct() %>%
  arrange(site)

site_date = cross_join(sites,
                       dates)

df_agg <- bd_model %>%
  filter(bd_detected_co) %>%
  group_by(date, site) %>%
  summarise(mean_log_load = mean(log_bd_load_co_density, na.rm = TRUE),
            n = n(),
            .groups='drop')

full_agg = site_date %>%
  left_join(df_agg, by = c("site", "date")) %>%
  left_join(ts_in, by = c("site", "date"))

adp = full_agg %>%
  filter(site == "altos_de_piedra") %>%
  select(-site)


peace <- vector("list", nrow(sites))
for (i in seq_len(nrow(sites))) {
  site_name <- sites$site[i]  # Adjust column name if needed (e.g., sites$site)
  peace[[i]] <- acf(full_agg %>%
                       filter(site == site_name) %>%
                       arrange(date) %>%
                       pull(precipitation_mm), 
                     lag.max = 90)
}

acf_df <- map_dfr(seq_along(peace), function(i) {
  tibble(
    site = i,
    lag = 0:(length(peace[[i]]$acf[, 1, 1]) - 1),
    acf = peace[[i]]$acf[, 1, 1]
  )
})

mean_acf_df <- acf_df %>%
  group_by(lag) %>%
  summarise(mean_acf = mean(acf, na.rm = TRUE), .groups = "drop")

ggplot(mean_acf_df, aes(lag, mean_acf)) +
  geom_hline(yintercept = 0, color = "red") +
  geom_bar(stat = "identity") +
  labs(title = "Mean ACF Across Replicate Sites")


```
